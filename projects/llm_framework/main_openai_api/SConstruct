import os

Import('env')
with open(env['PROJECT_TOOL_S']) as f:
    exec(f.read())

# env.Append(CXXFLAGS=['-O3', '-fopenmp', '-std=c++17'])
SRCS = append_srcs_dir(ADir('src'))
INCLUDE = [ADir('include'), ADir('.')]
PRIVATE_INCLUDE = []
REQUIREMENTS = ['pthread']
STATIC_LIB = []
DYNAMIC_LIB = []
DEFINITIONS = []
DEFINITIONS_PRIVATE = []
LDFLAGS = []
LINK_SEARCH_PATH = []
STATIC_FILES = []

ModuleLLMOpenAIPluginPath = os.path.join(os.environ['GIT_REPO_PATH'], 'ModuleLLM-OpenAI-Plugin')
if not os.path.exists(ModuleLLMOpenAIPluginPath):
    wget_github_commit('https://github.com/Abandon-ht/ModuleLLM-OpenAI-Plugin.git', '1077efbe201ea3f29517f5ce4a0cfc3b04c25d1d')


python_venv = check_wget_down("https://m5stack.oss-cn-shenzhen.aliyuncs.com/resource/linux/llm/m5stack_llm-openai-api-python-venv_v1.5.tar.gz", 'm5stack_llm-llm-openai-api-python-venv_v1.5.tar.gz')


DEFINITIONS += ['-O3', '-fopenmp', '-std=c++17']
LDFLAGS+=['-Wl,-rpath=/opt/m5stack/lib', '-Wl,-rpath=/usr/local/m5stack/lib', '-Wl,-rpath=/usr/local/m5stack/lib/gcc-10.3', '-Wl,-rpath=/opt/lib', '-Wl,-rpath=/opt/usr/lib', '-Wl,-rpath=./']
LINK_SEARCH_PATH += [ADir('../static_lib')]

STATIC_FILES += Glob('mode_*.json')


STATIC_FILES += [ModuleLLMOpenAIPluginPath]
STATIC_FILES += [os.path.join(python_venv, 'openai-api')]

env['COMPONENTS'].append({'target':'llm_openai_api',
                          'SRCS':SRCS,
                          'INCLUDE':INCLUDE,
                          'PRIVATE_INCLUDE':PRIVATE_INCLUDE,
                          'REQUIREMENTS':REQUIREMENTS,
                          'STATIC_LIB':STATIC_LIB,
                          'DYNAMIC_LIB':DYNAMIC_LIB,
                          'DEFINITIONS':DEFINITIONS,
                          'DEFINITIONS_PRIVATE':DEFINITIONS_PRIVATE,
                          'LDFLAGS':LDFLAGS,
                          'LINK_SEARCH_PATH':LINK_SEARCH_PATH,
                          'STATIC_FILES':STATIC_FILES,
                          'REGISTER':'project'
                          })
