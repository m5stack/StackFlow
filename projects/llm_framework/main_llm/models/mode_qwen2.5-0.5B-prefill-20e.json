{
    "mode":"qwen2.5-0.5B-prefill-20e",
    "type":"llm",
    "homepage":"https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct",
    "compile_flage":"pulsar2 llm_build --input_path Qwen/Qwen2-0.5B-Instruct/ --output_path Qwen/Qwen2-0.5B-w8a16/ --kv_cache_len 1023 --hidden_state_type bf16 --prefill_len 128 --chip AX620E;./tools/embed_process.sh Qwen/Qwen2-0.5B-Instruct/ Qwen/Qwen2-0.5B-w8a16/",
    "pulsar_version":"3.4-983bb35e",
    "capabilities":[
        "text_generation",
        "chat"
    ],
    "input_type":[
        "llm.utf-8",
        "llm.utf-8.stream",
        "llm.chat_completion",
        "llm.chat_completion.stream"
    ],
    "output_type":[
        "llm.utf-8",
        "llm.utf-8.stream"
    ],
    "mode_param":{
        "tokenizer_type":1,
        "filename_tokenizer_model":"qwen.tiktoken",
        "filename_tokens_embed":"model.embed_tokens.weight.bfloat16.bin",
        "filename_post_axmodel":"qwen2_post.axmodel",
        "template_filename_axmodel":"qwen2_p128_l%d_together.axmodel",
        "b_use_topk":false,
        "b_bos":false,
        "b_eos":false,
        "axmodel_num":24,
        "tokens_embed_num":151936,
        "tokens_embed_size":896,
        "b_use_mmap_load_embed":true,
        "b_dynamic_load_axmodel_layer":false
    }
}