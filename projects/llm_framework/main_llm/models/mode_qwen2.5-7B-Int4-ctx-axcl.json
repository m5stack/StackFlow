{
    "mode": "qwen2.5-7B-Int4-ctx-axcl",
    "type": "llm",
    "homepage": "https://huggingface.co/AXERA-TECH/Qwen2.5-7B-Instruct-GPTQ-Int4",
    "compile_flage": "pulsar2 llm_build --input_path Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4/ --output_path Qwen/qwen2.5-7b-gptq_int4-p1024-ax650 --hidden_state_type bf16 --prefill_len 128 --kv_cache_len 1280 --last_kv_cache_len 128 --last_kv_cache_len 512 --last_kv_cache_len 1024 --chip AX650 -w s4 --parallel 16",
    "pulsar_version": "5.0-patch1-fd447d0d",
    "capabilities": [
        "text_generation",
        "chat"
    ],
    "input_type": [
        "llm.utf-8",
        "llm.utf-8.stream",
        "llm.chat_completion",
        "llm.chat_completion.stream"
    ],
    "output_type": [
        "llm.utf-8",
        "llm.utf-8.stream"
    ],
    "mode_param": {
        "tokenizer_type": 2,
        "url_tokenizer_model": "http://localhost:8080",
        "filename_tokens_embed": "model.embed_tokens.weight.bfloat16.bin",
        "filename_post_axmodel": "qwen2_post.axmodel",
        "template_filename_axmodel": "qwen2_p128_l%d_together.axmodel",
        "enable_temperature": true,
        "temperature": 0.7,
        "enable_top_p_sampling": false,
        "top_p": 0.9,
        "enable_top_k_sampling": true,
        "top_k": 40,
        "enable_repetition_penalty": false,
        "repetition_penalty": 1.1,
        "penalty_window": 50,
        "axmodel_num": 28,
        "tokens_embed_num": 152064,
        "tokens_embed_size": 3584,
        "b_use_mmap_load_embed": true,
        "precompute_len": 2048,
        "cmm_size": 4513232,
        "ext_scripts": [
            "tokenizer_qwen2.5-7B-Int4-ctx-axcl.py"
        ]
    }
}